---
title:  "Docker: Up & Running in Under a Week"
date:   2017-06-21 11:00:00 -0600
categories: web development
tags: docker
---
I've been avoiding it for some time now. After over 8 hours* of video courses and a working development environment in 2 to 3 days, I am ready to write about my experience. What prompted this ramp-up of interest in Docker? I was working with a member of my devops team to get a new site setup with continuous integretation and deployed to AWS Elastic Beanstalk (EB), when he said that they support deployments with Docker Containers with a [how to link][aws-eb-and-docker].

<small>*\* I didn't actually watch 8 hours of content thanks to 2x playback speed, and skipping Windows specific segments since I'm on a Mac.*</small>

## Overview

This is not an article about why you should use Docker, or what it can do for you. If you're not familiar with Docker, you can find out more on [their site](https://www.docker.com/what-docker). At work I have a [Pluralsight](https://www.pluralsight.com/) subscription, and I have watched three videos so far that have helped broaden my understanding:
* [Docker and Containers: The Big Picture](https://app.pluralsight.com/library/courses/docker-containers-big-picture), by Nigel Poulton
* [Getting Started with Docker](https://app.pluralsight.com/library/courses/docker-getting-started), by Nigel Poulton
* [Docker for Web Developers](https://app.pluralsight.com/library/courses/docker-web-development), by Dan Wahlin

## Configuration

I have two Docker containers for this project, one for an API and the other for static React content. 

### api.dockerfile

{% highlight dockerfile %}
FROM node:6.10.0

ENV NODE_ENV=development
ENV PORT=10010

COPY . /var/www
WORKDIR /var/www

RUN npm install

EXPOSE $PORT

ENTRYPOINT ["npm", "run", "serv"]
{% endhighlight %}
<br />
Lets take this a few lines at a time.

{% highlight dockerfile %}
FROM node:6.10.0
{% endhighlight %}

This probably doesn't need much explanation. It will use the Node.js v6.10.0 image, first checking your local images for a copy, and if it's not there, pulling (i.e. downloading) it from the Docker Store. Why 6.10.0, and not something newer? This is the [latest LTS version currently supported][aws-nodejs-docs] by my EB version.

{% highlight dockerfile %}
ENV NODE_ENV=development
ENV PORT=10010
{% endhighlight %}

You can set Node variables in the Dockerfile that will be accessible throughout your node app. My app will use these to determine what config file to use and to set the port.

{% highlight dockerfile %}
COPY . /var/www
WORKDIR /var/www
{% endhighlight %}

The first command, `COPY`, is copying the contents of my entire application into the directory `/var/www/`. Since I want to be able to run commands from this directory, I set the working directory, `WORKDIR`, to point to this location as well. It doesn't have to be `/var/www/`, it could have been anywhere really, but I chose to stick with the example from the video course I was watching.

{% highlight dockerfile %}
RUN npm install
{% endhighlight %}

This is the same as typing `npm install` in the console - it will install all the dependencies in my `package.json` file.

{% highlight dockerfile %}
EXPOSE $PORT
{% endhighlight %}

The Docker container will run on the `$PORT`, which we defined earlier in `ENV PORT=10010`, and matches the port the node app is running on.

{% highlight dockerfile %}
ENTRYPOINT ["npm", "run", "serv"]
{% endhighlight %}

Finally, the `ENTRYPOINT` is the command my app will run on after it starts up. In this case, `serv` is an npm script I have set up in my `package.json` file to start the server.

### react.dockerfile

{% highlight dockerfile %}
FROM nginx
COPY build /usr/share/nginx/html
{% endhighlight %}
<br />
This is a lot simpler. We get the latest image of `nginx`, and then copy the files from the `build` directly into `/usr/share/nginx/html`, where they will be served up statically. Piece of cake.

## Build, run, and prosper

At first I was using the command line tools to build and run each Docker file individually. It's simple enough with just two containers, but complexity goes up as you increase the number of containers and isn't a very efficient use of your time. Here is the code:

{% highlight console %}
$ docker build -f api.dockerfile -t investor-portal-api .
$ docker build -f react.dockerfile -t investor-portal-react .

$ docker run -d --rm -p 10010:10010 --name investor-portal-api investor-portal-api
$ docker run -d --rm --link investor-portal-api -p 3000:80 --name investor-portal-react investor-portal-react
{% endhighlight %}

The `docker build` command should only have to be run once, unless you make changes to the Dockerfile. The `-f` flag is to designate the file, which isn't necessary if you give it the default name of `Dockerfile`. `-t` flag is for tag, so you can give your image a name.

`docker run` has a few flags as well: `-d` is for detached, so it will run the container in the background and still give you access to the console on your machine. Alternatively, you could give use the flag `-it` for an interactive terminal, which would allow you to run terminal commands on the container after it starts. According to [Docker documentation](https://docs.docker.com/engine/reference/run/#clean-up-rm), the `-rm` flag will "automatically clean up the container and remove the file system when the container exits". This is important because otherwise the file system for the container will remain after you stop the container. `--link investor-portal-api` is in the second `run` command, and links the second container to the first so they can communicate via a private networking interface. To expose the port, use `-p <external port>:<internal port>`. In the case of the `investor-portal-react`, when running it locally, it can be accessed at `http://localhost:3000`. You can give your container a name using `--name`. Finally, provide the name of the image (i.e. the tag name we used when we did the `build` step). In this case, I decided to name the container and the image the same thing, so don't be confused by that.

## Docker Compose FTW!

Docker Compose is a beautiful thing friends! It is another product offered by Docker that can manage the entire app lifecycle. With it you can:
* Start, stop, and rebuild services
* View the status of running services
* Stream the log output
* Run one-off commands on a service

### docker-compose.yml

For starts, you need a `docker-compose.yml` file. This will include all the info Docker Compose needs to build, run, and manage all of your services (i.e. containers).

{% highlight yaml %}
version: '3'

services:
  api:
    build:
      context: .
      dockerfile: api.dockerfile
    ports:
      - "10010:10010"
    networks:
      - nodeapp-network

  react:
    build:
      context: .
      dockerfile: react.dockerfile
    ports:
      - "3000:80"
    networks:
      - nodeapp-network

networks:
  nodeapp-network:
    driver: bridge
{% endhighlight %}

The latest version as of the time of this writing is `version: '3'`. You can check the compatibility table [here](https://docs.docker.com/compose/compose-file/compose-versioning/). I definitely recommend going with the latest compatible version.

Next I have a section for `services`, which contains my two services: `api` and `react`. Each of these have a `build` section, where I set the `context` to the current directory and tell it which `dockerfile` to use. Next is the `ports` section, which is the same as our `-p <external port>:<internal port>` that we would use in the command line. Last, there is a section for `networks` (inside each service), which is the name of the network we create in the final top level section.

`networks` is our way of linking up containers. In the command line, we did `--link container_name_linking_to`, but this is another way to accomplish the same thing. We just add each service to the private network, where we want them to be able to communicate with each other. You just give it a name, I called it `nodeapp-network`, and tell it what `driver` to use. To be honest, I don't know what the other optiosn for driver do, but `bridge` is working for me. It is possible to have multiple networks and place services in one or more networks, so you can have isolated groups of containers. Fortunately, nothing so complicated is needed here.

### Docker Compose Commands

Docker Compose simplifies the commands we need to get our containers up and running. The commands are `docker-compose <command name>`, so `docker-compose build` is an example command we would use to build our images. Command names:
* `build` - build or rebuild images
* `up` - start up images as containers
* `down` - tear down running containers (stop and remove)
* `logs`- view the logs
* `ps` - list the containers running
* `stop` - stop different services
* `start` - start them back up
* `rm` - remove containers

Just for comparisons, without Docker Compose, to run one container we would enter this command `docker run -d --rm -p 10010:10010 --name investor-portal-api investor-portal-api`. Now, with Docker Compose, we can just run `docker-compose up`, and not only will it run one container, but it will run all of them in the `docker-compose.yml`. We still have the option of running only one container as well by just using the service's name: `docker-compose up api`.

## What's Next

So far I only have this running on my local machine. That's pretty cool, but the reason I started down this route is the [article][aws-eb-and-docker] my devops team mate sent me. So the next step is to get these Docker containers working in a stage environment. Also, there a few more video courses on Pluralsight that I'm interested in about Docker, including [Docker Deep Dive](https://app.pluralsight.com/player?course=docker-deep-dive&author=nigel-poulton&name=docker-deep-dive-m0&clip=0) and [Integrating Docker with DevOps Automated Workflows](https://app.pluralsight.com/player?course=integrating-docker-with-devops-automated-workflows&author=nigel-poulton&name=integrating-docker-with-devops-automated-workflows-m1&clip=0), both by Nigel Poulton.

[aws-nodejs-docs]: http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html#concepts.platforms.nodejs
[aws-eb-and-docker]: http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html
